{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c89167",
   "metadata": {},
   "source": [
    "# Bike Sharing Dataset\n",
    "## Data Cleaning & Vector Space Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f408132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ucimlrepo import fetch_ucirepo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fd1298",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7621c747",
   "metadata": {},
   "source": [
    "See first rows of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91420fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Bike Sharing\n",
      "Description: This dataset contains the hourly and daily count of rental bikes between years 2011 and 2012 in Capital bikeshare system with the corresponding weather and seasonal information.\n",
      "Dataset features: 2013\n",
      "None\n",
      "       cnt\n",
      "0       16\n",
      "1       40\n",
      "2       32\n",
      "3       13\n",
      "4        1\n",
      "...    ...\n",
      "17374  119\n",
      "17375   89\n",
      "17376   90\n",
      "17377   61\n",
      "17378   49\n",
      "\n",
      "[17379 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  \n",
    "# fetch dataset \n",
    "# dataset url https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset\n",
    "\n",
    "bike_sharing = fetch_ucirepo(id=275)\n",
    "\n",
    "print(f\"Dataset {bike_sharing.metadata['name']}\")\n",
    "print(f\"Description: {bike_sharing.metadata['abstract']}\")\n",
    "print(f\"Created {bike_sharing.metadata['year_of_dataset_creation']}\")\n",
    "# data\n",
    "X = bike_sharing.data.other \n",
    "print(X)\n",
    "y = bike_sharing.data.targets \n",
    "print(y)\n",
    "  \n",
    "df = pd.DataFrame(X, columns=bike_sharing.data.feature_names)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b2feb",
   "metadata": {},
   "source": [
    "## Initial Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa07fc",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a761215b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
       "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1283dea0",
   "metadata": {},
   "source": [
    "Data represents bike rental (sharing) system.\n",
    "\n",
    "There are 17 columns:\n",
    "- **instant:** record index\n",
    "- **dteday:** date\n",
    "- **season:** 1:winter, 2:spring, 3:summer, 4:fall\n",
    "- **yr:** year (0: 2011, 1: 2012)\n",
    "- **mnth:** month (1 to 12)\n",
    "- **hr:** hour (0 to 23)\n",
    "- **holiday:** weather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)\n",
    "- **weekday:** day of the week\n",
    "- **workingday:** if day is neither weekend nor holiday is 1, otherwise is 0\n",
    "- **weathersit:** \n",
    "    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "\t- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "\t- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "\t- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "- **temp:** Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n",
    "- **atemp:** Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n",
    "- **hum:** Normalized humidity. The values are divided to 100 (max)\n",
    "- **windspeed:** Normalized wind speed. The values are divided to 67 (max)\n",
    "- **casual:** count of casual users\n",
    "- **registered:** count of registered users\n",
    "- **cnt:** count of total rental bikes including both casual and registered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff51a63c",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------\n",
    "See more info about the dataset... There is a rule that the columns should not have a null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0974148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   dteday      17379 non-null  str    \n",
      " 1   season      17379 non-null  int64  \n",
      " 2   yr          17379 non-null  int64  \n",
      " 3   mnth        17379 non-null  int64  \n",
      " 4   hr          17379 non-null  int64  \n",
      " 5   holiday     17379 non-null  int64  \n",
      " 6   weekday     17379 non-null  int64  \n",
      " 7   workingday  17379 non-null  int64  \n",
      " 8   weathersit  17379 non-null  int64  \n",
      " 9   temp        17379 non-null  float64\n",
      " 10  atemp       17379 non-null  float64\n",
      " 11  hum         17379 non-null  float64\n",
      " 12  windspeed   17379 non-null  float64\n",
      "dtypes: float64(4), int64(8), str(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17379.000000</td>\n",
       "      <td>17379.000000</td>\n",
       "      <td>17379.000000</td>\n",
       "      <td>17379.000000</td>\n",
       "      <td>17379.000000</td>\n",
       "      <td>17379.000000</td>\n",
       "      <td>17379.000000</td>\n",
       "      <td>17379.000000</td>\n",
       "      <td>17379.000000</td>\n",
       "      <td>17379.000000</td>\n",
       "      <td>17379.000000</td>\n",
       "      <td>17379.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.501640</td>\n",
       "      <td>0.502561</td>\n",
       "      <td>6.537775</td>\n",
       "      <td>11.546752</td>\n",
       "      <td>0.028770</td>\n",
       "      <td>3.003683</td>\n",
       "      <td>0.682721</td>\n",
       "      <td>1.425283</td>\n",
       "      <td>0.496987</td>\n",
       "      <td>0.475775</td>\n",
       "      <td>0.627229</td>\n",
       "      <td>0.190098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.106918</td>\n",
       "      <td>0.500008</td>\n",
       "      <td>3.438776</td>\n",
       "      <td>6.914405</td>\n",
       "      <td>0.167165</td>\n",
       "      <td>2.005771</td>\n",
       "      <td>0.465431</td>\n",
       "      <td>0.639357</td>\n",
       "      <td>0.192556</td>\n",
       "      <td>0.171850</td>\n",
       "      <td>0.192930</td>\n",
       "      <td>0.122340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.104500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.621200</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.253700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             season            yr          mnth            hr       holiday  \\\n",
       "count  17379.000000  17379.000000  17379.000000  17379.000000  17379.000000   \n",
       "mean       2.501640      0.502561      6.537775     11.546752      0.028770   \n",
       "std        1.106918      0.500008      3.438776      6.914405      0.167165   \n",
       "min        1.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      4.000000      6.000000      0.000000   \n",
       "50%        3.000000      1.000000      7.000000     12.000000      0.000000   \n",
       "75%        3.000000      1.000000     10.000000     18.000000      0.000000   \n",
       "max        4.000000      1.000000     12.000000     23.000000      1.000000   \n",
       "\n",
       "            weekday    workingday    weathersit          temp         atemp  \\\n",
       "count  17379.000000  17379.000000  17379.000000  17379.000000  17379.000000   \n",
       "mean       3.003683      0.682721      1.425283      0.496987      0.475775   \n",
       "std        2.005771      0.465431      0.639357      0.192556      0.171850   \n",
       "min        0.000000      0.000000      1.000000      0.020000      0.000000   \n",
       "25%        1.000000      0.000000      1.000000      0.340000      0.333300   \n",
       "50%        3.000000      1.000000      1.000000      0.500000      0.484800   \n",
       "75%        5.000000      1.000000      2.000000      0.660000      0.621200   \n",
       "max        6.000000      1.000000      4.000000      1.000000      1.000000   \n",
       "\n",
       "                hum     windspeed  \n",
       "count  17379.000000  17379.000000  \n",
       "mean       0.627229      0.190098  \n",
       "std        0.192930      0.122340  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.480000      0.104500  \n",
       "50%        0.630000      0.194000  \n",
       "75%        0.780000      0.253700  \n",
       "max        1.000000      0.850700  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.info()\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82580c4",
   "metadata": {},
   "source": [
    "- **count** - the final number of the non-null values (the result: the dataset didn't have NaN values so matching to 17 329 rows)\n",
    "- **mean** - the average of the values in the each column\n",
    "- **std** - the standard deviation (how spread out the data are -> low value: close to the mean, high value: data points are spread out wider)\n",
    "- **min** - the smallest value in the each column\n",
    "- **25%** - the value closest to the 25% metric of data\n",
    "- **50%** - the value closest to the 50% metric of data\n",
    "- **75%** - the value closest to the 75% metric of data\n",
    "- **max** - the highest value in the each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d8e88",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------\n",
    "Number of rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6458da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d24f9f2",
   "metadata": {},
   "source": [
    "**Rows:** 17 379\n",
    "\n",
    "**Columns:** 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eaea02",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------\n",
    "### Analyze Data Structure\n",
    "Count elements (distinct):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73ae1a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dteday        731\n",
       "season          4\n",
       "yr              2\n",
       "mnth           12\n",
       "hr             24\n",
       "holiday         2\n",
       "weekday         7\n",
       "workingday      2\n",
       "weathersit      4\n",
       "temp           50\n",
       "atemp          65\n",
       "hum            89\n",
       "windspeed      30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e6139d",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "***.isna()***: creates a table of booleans, where **True** is for **NaN**, the we sum them (***.sum()***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c9f9ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dteday        0\n",
      "season        0\n",
      "yr            0\n",
      "mnth          0\n",
      "hr            0\n",
      "holiday       0\n",
      "weekday       0\n",
      "workingday    0\n",
      "weathersit    0\n",
      "temp          0\n",
      "atemp         0\n",
      "hum           0\n",
      "windspeed     0\n",
      "dtype: int64\n",
      "\n",
      "### Missing values (%): ###\n",
      "dteday        0.0\n",
      "season        0.0\n",
      "yr            0.0\n",
      "mnth          0.0\n",
      "hr            0.0\n",
      "holiday       0.0\n",
      "weekday       0.0\n",
      "workingday    0.0\n",
      "weathersit    0.0\n",
      "temp          0.0\n",
      "atemp         0.0\n",
      "hum           0.0\n",
      "windspeed     0.0\n",
      "dtype: float64\n",
      "\n",
      "### Total duplicate rows: 0\n",
      "### Duplicates (keep first): 0\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "sum_nan_values = df.isna().sum()\n",
    "print(sum_nan_values)\n",
    "print(\"\\n### Missing values (%): ###\")\n",
    "print((sum_nan_values / len(df) * 100).round(2))\n",
    "\n",
    "# Duplicates\n",
    "print(f\"\\n### Total duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"### Duplicates (keep first): {df.duplicated(keep='first').sum()}\")\n",
    "\n",
    "# Remove duplicates if needed\n",
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3658d39b",
   "metadata": {},
   "source": [
    "From the output is visible that there ae not missing values, also no duplicate rows. Overall, data quality looks clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc6461",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5eda8a",
   "metadata": {},
   "source": [
    "Drop non-informative columns\n",
    "- **instant:** just a sequence index, no predictive value\n",
    "- **dteday:** date string, hour already captures temporal patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7f30268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after cleaning: ['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
      "Shape: (17379, 12)\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.drop(columns=[ \"dteday\"])\n",
    "\n",
    "print(f\"Columns after cleaning: {df_clean.columns.tolist()}\")\n",
    "print(f\"Shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4264d2",
   "metadata": {},
   "source": [
    "Validate data integrity for data consistency issues: casual users + registered users should equal total count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e340097",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'casual'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/au/02_data_mining/project/DM-Project/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'casual'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m validation_error = (\u001b[43mdf_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcasual\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m + df_clean[\u001b[33m\"\u001b[39m\u001b[33mregistered\u001b[39m\u001b[33m\"\u001b[39m] - df_clean[\u001b[33m\"\u001b[39m\u001b[33mcnt\u001b[39m\u001b[33m\"\u001b[39m]).abs().sum()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mData integrity check (should be 0): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validation_error == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/au/02_data_mining/project/DM-Project/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/au/02_data_mining/project/DM-Project/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'casual'"
     ]
    }
   ],
   "source": [
    "validation_error = (df_clean[\"casual\"] + df_clean[\"registered\"] - df_clean[\"cnt\"]).abs().sum()\n",
    "\n",
    "print(f\"Data integrity check (should be 0): {validation_error}\")\n",
    "\n",
    "if validation_error == 0:\n",
    "    print(\"Data is consistent: casual + registered = cnt\")\n",
    "else:\n",
    "    print(\"Data is inconsistent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f8195",
   "metadata": {},
   "source": [
    "## Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107b852",
   "metadata": {},
   "source": [
    "***pd.get_dummies():*** converts **categorical** type columns into multiple columns (also called one-hot encoding) with boolean values\n",
    "- **season:** has values like 1, 2, 3, 4, it becomes columns like spring, summer, fall, winter \n",
    "- **year:** from 0 and 1 to specific years,\n",
    "- **weekday:** from numbers to days\n",
    "- **weathersit:** from numbers to weather status\n",
    "- other categorical data (month and hour we kept as values in one column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b1d1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after encoding: ['mnth', 'hr', 'holiday', 'workingday', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt', 'season_fall', 'season_spring', 'season_summer', 'season_winter', 'year_2011', 'year_2012', 'weekday_Friday', 'weekday_Monday', 'weekday_Saturday', 'weekday_Sunday', 'weekday_Thursday', 'weekday_Tuesday', 'weekday_Wednesday', 'weathersit_Clear/Few clouds', 'weathersit_Heavy Rain/Snow', 'weathersit_Light Snow/Rain', 'weathersit_Mist/Cloudy']\n",
      "Shape after encoding: (17379, 28)\n",
      "\n",
      "Data types:\n",
      "mnth                             int64\n",
      "hr                               int64\n",
      "holiday                          int64\n",
      "workingday                       int64\n",
      "temp                           float64\n",
      "atemp                          float64\n",
      "hum                            float64\n",
      "windspeed                      float64\n",
      "casual                           int64\n",
      "registered                       int64\n",
      "cnt                              int64\n",
      "season_fall                       bool\n",
      "season_spring                     bool\n",
      "season_summer                     bool\n",
      "season_winter                     bool\n",
      "year_2011                         bool\n",
      "year_2012                         bool\n",
      "weekday_Friday                    bool\n",
      "weekday_Monday                    bool\n",
      "weekday_Saturday                  bool\n",
      "weekday_Sunday                    bool\n",
      "weekday_Thursday                  bool\n",
      "weekday_Tuesday                   bool\n",
      "weekday_Wednesday                 bool\n",
      "weathersit_Clear/Few clouds       bool\n",
      "weathersit_Heavy Rain/Snow        bool\n",
      "weathersit_Light Snow/Rain        bool\n",
      "weathersit_Mist/Cloudy            bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "season_labels = {1: \"spring\", 2: \"summer\", 3: \"fall\", 4: \"winter\"}\n",
    "year_labels = {0: \"2011\", 1: \"2012\"}\n",
    "weekday_labels = {0: \"Sunday\", 1: \"Monday\", 2: \"Tuesday\", 3: \"Wednesday\", 4: \"Thursday\", 5: \"Friday\", 6: \"Saturday\"}\n",
    "weathersit_labels = {1: \"Clear/Few clouds\", 2: \"Mist/Cloudy\", 3: \"Light Snow/Rain\", 4: \"Heavy Rain/Snow\"}\n",
    "\n",
    "season_dummies = pd.get_dummies(df_clean[\"season\"].map(season_labels), prefix=\"season\")\n",
    "year_dummies = pd.get_dummies(df_clean[\"yr\"].map(year_labels), prefix=\"year\")\n",
    "weekday_dummies = pd.get_dummies(df_clean[\"weekday\"].map(weekday_labels), prefix=\"weekday\")\n",
    "weathersit_dummies = pd.get_dummies(df_clean[\"weathersit\"].map(weathersit_labels), prefix=\"weathersit\")\n",
    "\n",
    "df_encoded = pd.concat([\n",
    "    df_clean.drop(columns=[\"season\", \"weathersit\", \"weekday\", \"yr\"]),\n",
    "    season_dummies,\n",
    "    year_dummies,\n",
    "    weekday_dummies,\n",
    "    weathersit_dummies\n",
    "], axis=1)\n",
    "\n",
    "print(f\"Columns after encoding: {df_encoded.columns.tolist()}\")\n",
    "print(f\"Shape after encoding: {df_encoded.shape}\")\n",
    "print(f\"\\nData types:\\n{df_encoded.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f54b342",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145e6f8",
   "metadata": {},
   "source": [
    "Standardize numerical features to zero mean and unit variance - this could be an optional step\n",
    "> Note: 'hr' is kept unscaled as it's cyclical (others can be as well if decided that it is unnecessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a72849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling verification (should be ~0 mean, ~1 std):\n",
      "\n",
      "Means:\n",
      "temp          0.0\n",
      "atemp        -0.0\n",
      "hum           0.0\n",
      "windspeed     0.0\n",
      "cnt          -0.0\n",
      "casual        0.0\n",
      "registered   -0.0\n",
      "dtype: float64\n",
      "\n",
      "Std Devs:\n",
      "temp          1.0\n",
      "atemp         1.0\n",
      "hum           1.0\n",
      "windspeed     1.0\n",
      "cnt           1.0\n",
      "casual        1.0\n",
      "registered    1.0\n",
      "dtype: float64\n",
      "\n",
      "Note: 'hr' column kept unscaled (range 0-23)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "numerical_cols = [\n",
    "    \"temp\", \"atemp\", \"hum\", \"windspeed\",\n",
    "    \"cnt\", \"casual\", \"registered\"\n",
    "]\n",
    "\n",
    "df_encoded[numerical_cols] = scaler.fit_transform(\n",
    "    df_encoded[numerical_cols]\n",
    ")\n",
    "\n",
    "print(\"Scaling verification (should be ~0 mean, ~1 std):\")\n",
    "print(f\"\\nMeans:\\n{df_encoded[numerical_cols].mean().round(4)}\")\n",
    "print(f\"\\nStd Devs:\\n{df_encoded[numerical_cols].std().round(4)}\")\n",
    "print(f\"\\nNote: 'hr' column kept unscaled (range 0-23)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f7875",
   "metadata": {},
   "source": [
    "## Final Dataset Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4a689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "Shape: (17379, 28)\n",
      "\n",
      "First 5 rows:\n",
      "   mnth  hr  holiday  workingday      temp     atemp       hum  windspeed  \\\n",
      "0     1   0        0           0 -1.334648 -1.093281  0.947372  -1.553889   \n",
      "1     1   1        0           0 -1.438516 -1.181732  0.895539  -1.553889   \n",
      "2     1   2        0           0 -1.438516 -1.181732  0.895539  -1.553889   \n",
      "3     1   3        0           0 -1.334648 -1.093281  0.636370  -1.553889   \n",
      "4     1   4        0           0 -1.334648 -1.093281  0.636370  -1.553889   \n",
      "\n",
      "     casual  registered  ...  weekday_Monday  weekday_Saturday  \\\n",
      "0 -0.662755   -0.930189  ...           False              True   \n",
      "1 -0.561343   -0.804655  ...           False              True   \n",
      "2 -0.622190   -0.837690  ...           False              True   \n",
      "3 -0.662755   -0.950010  ...           False              True   \n",
      "4 -0.723603   -1.009474  ...           False              True   \n",
      "\n",
      "   weekday_Sunday  weekday_Thursday  weekday_Tuesday  weekday_Wednesday  \\\n",
      "0           False             False            False              False   \n",
      "1           False             False            False              False   \n",
      "2           False             False            False              False   \n",
      "3           False             False            False              False   \n",
      "4           False             False            False              False   \n",
      "\n",
      "   weathersit_Clear/Few clouds  weathersit_Heavy Rain/Snow  \\\n",
      "0                         True                       False   \n",
      "1                         True                       False   \n",
      "2                         True                       False   \n",
      "3                         True                       False   \n",
      "4                         True                       False   \n",
      "\n",
      "   weathersit_Light Snow/Rain  weathersit_Mist/Cloudy  \n",
      "0                       False                   False  \n",
      "1                       False                   False  \n",
      "2                       False                   False  \n",
      "3                       False                   False  \n",
      "4                       False                   False  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 28 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   mnth                         17379 non-null  int64  \n",
      " 1   hr                           17379 non-null  int64  \n",
      " 2   holiday                      17379 non-null  int64  \n",
      " 3   workingday                   17379 non-null  int64  \n",
      " 4   temp                         17379 non-null  float64\n",
      " 5   atemp                        17379 non-null  float64\n",
      " 6   hum                          17379 non-null  float64\n",
      " 7   windspeed                    17379 non-null  float64\n",
      " 8   casual                       17379 non-null  float64\n",
      " 9   registered                   17379 non-null  float64\n",
      " 10  cnt                          17379 non-null  float64\n",
      " 11  season_fall                  17379 non-null  bool   \n",
      " 12  season_spring                17379 non-null  bool   \n",
      " 13  season_summer                17379 non-null  bool   \n",
      " 14  season_winter                17379 non-null  bool   \n",
      " 15  year_2011                    17379 non-null  bool   \n",
      " 16  year_2012                    17379 non-null  bool   \n",
      " 17  weekday_Friday               17379 non-null  bool   \n",
      " 18  weekday_Monday               17379 non-null  bool   \n",
      " 19  weekday_Saturday             17379 non-null  bool   \n",
      " 20  weekday_Sunday               17379 non-null  bool   \n",
      " 21  weekday_Thursday             17379 non-null  bool   \n",
      " 22  weekday_Tuesday              17379 non-null  bool   \n",
      " 23  weekday_Wednesday            17379 non-null  bool   \n",
      " 24  weathersit_Clear/Few clouds  17379 non-null  bool   \n",
      " 25  weathersit_Heavy Rain/Snow   17379 non-null  bool   \n",
      " 26  weathersit_Light Snow/Rain   17379 non-null  bool   \n",
      " 27  weathersit_Mist/Cloudy       17379 non-null  bool   \n",
      "dtypes: bool(17), float64(7), int64(4)\n",
      "memory usage: 1.7 MB\n",
      "\n",
      "Basic Statistics:\n",
      "            mnth         hr    holiday  workingday       temp      atemp  \\\n",
      "count  17379.000  17379.000  17379.000   17379.000  17379.000  17379.000   \n",
      "mean       6.538     11.547      0.029       0.683      0.000     -0.000   \n",
      "std        3.439      6.914      0.167       0.465      1.000      1.000   \n",
      "min        1.000      0.000      0.000       0.000     -2.477     -2.769   \n",
      "25%        4.000      6.000      0.000       0.000     -0.815     -0.829   \n",
      "50%        7.000     12.000      0.000       1.000      0.016      0.053   \n",
      "75%       10.000     18.000      0.000       1.000      0.847      0.846   \n",
      "max       12.000     23.000      1.000       1.000      2.612      3.051   \n",
      "\n",
      "             hum  windspeed     casual  registered        cnt  \n",
      "count  17379.000  17379.000  17379.000   17379.000  17379.000  \n",
      "mean       0.000      0.000      0.000      -0.000     -0.000  \n",
      "std        1.000      1.000      1.000       1.000      1.000  \n",
      "min       -3.251     -1.554     -0.724      -1.016     -1.039  \n",
      "25%       -0.763     -0.700     -0.642      -0.791     -0.824  \n",
      "50%        0.014      0.032     -0.379      -0.256     -0.262  \n",
      "75%        0.792      0.520      0.250       0.437      0.505  \n",
      "max        1.932      5.400      6.720       4.838      4.342  \n"
     ]
    }
   ],
   "source": [
    "# Final cleaned and processed dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {df_encoded.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df_encoded.head())\n",
    "print(f\"\\nData Info:\")\n",
    "df_encoded.info()\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(df_encoded.describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba493c1",
   "metadata": {},
   "source": [
    "## Vector Space Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1badaa13",
   "metadata": {},
   "source": [
    "Create feature vectors - each vector focuses on different aspect of behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9580ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_weather shape: (17379, 5) - Weather impact on bike usage\n",
      "X_users shape: (17379, 3) - User type segmentation by hour\n"
     ]
    }
   ],
   "source": [
    "# Weather Impact Vector:\n",
    "X_weather = df_encoded[[\"temp\", \"atemp\", \"hum\", \"windspeed\", \"cnt\"]].values\n",
    "\n",
    "# User Segmentation Vector\n",
    "X_users = df_encoded[[\"hr\", \"casual\", \"registered\"]].values\n",
    "\n",
    "print(f\"X_weather shape: {X_weather.shape} - Weather impact on bike usage\")\n",
    "print(f\"X_users shape: {X_users.shape} - User type segmentation by hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827aa755",
   "metadata": {},
   "source": [
    "## Repeat for day.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662a555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant       0\n",
      "dteday        0\n",
      "season        0\n",
      "yr            0\n",
      "mnth          0\n",
      "holiday       0\n",
      "weekday       0\n",
      "workingday    0\n",
      "weathersit    0\n",
      "temp          0\n",
      "atemp         0\n",
      "hum           0\n",
      "windspeed     0\n",
      "casual        0\n",
      "registered    0\n",
      "cnt           0\n",
      "dtype: int64\n",
      "\n",
      "Missing values (%):\n",
      "instant       0.0\n",
      "dteday        0.0\n",
      "season        0.0\n",
      "yr            0.0\n",
      "mnth          0.0\n",
      "holiday       0.0\n",
      "weekday       0.0\n",
      "workingday    0.0\n",
      "weathersit    0.0\n",
      "temp          0.0\n",
      "atemp         0.0\n",
      "hum           0.0\n",
      "windspeed     0.0\n",
      "casual        0.0\n",
      "registered    0.0\n",
      "cnt           0.0\n",
      "dtype: float64\n",
      "\n",
      "Total duplicate rows: 0\n",
      "Duplicates (keep first): 0\n",
      "Columns after cleaning: ['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt']\n",
      "Shape: (731, 14)\n",
      "Data integrity check (should be 0): 0\n",
      "Data is consistent: casual + registered = cnt\n",
      "Columns after encoding: ['mnth', 'holiday', 'workingday', 'temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt', 'season_fall', 'season_spring', 'season_summer', 'season_winter', 'year_2011', 'year_2012', 'weekday_Friday', 'weekday_Monday', 'weekday_Saturday', 'weekday_Sunday', 'weekday_Thursday', 'weekday_Tuesday', 'weekday_Wednesday', 'weathersit_Clear/Few clouds', 'weathersit_Light Snow/Rain', 'weathersit_Mist/Cloudy']\n",
      "Shape after encoding: (731, 26)\n",
      "\n",
      "Data types:\n",
      "mnth                             int64\n",
      "holiday                          int64\n",
      "workingday                       int64\n",
      "temp                           float64\n",
      "atemp                          float64\n",
      "hum                            float64\n",
      "windspeed                      float64\n",
      "casual                           int64\n",
      "registered                       int64\n",
      "cnt                              int64\n",
      "season_fall                       bool\n",
      "season_spring                     bool\n",
      "season_summer                     bool\n",
      "season_winter                     bool\n",
      "year_2011                         bool\n",
      "year_2012                         bool\n",
      "weekday_Friday                    bool\n",
      "weekday_Monday                    bool\n",
      "weekday_Saturday                  bool\n",
      "weekday_Sunday                    bool\n",
      "weekday_Thursday                  bool\n",
      "weekday_Tuesday                   bool\n",
      "weekday_Wednesday                 bool\n",
      "weathersit_Clear/Few clouds       bool\n",
      "weathersit_Light Snow/Rain        bool\n",
      "weathersit_Mist/Cloudy            bool\n",
      "dtype: object\n",
      "Dataset Overview:\n",
      "Shape: (17379, 28)\n",
      "\n",
      "First 5 rows:\n",
      "   mnth  hr  holiday  workingday      temp     atemp       hum  windspeed  \\\n",
      "0     1   0        0           0 -1.334648 -1.093281  0.947372  -1.553889   \n",
      "1     1   1        0           0 -1.438516 -1.181732  0.895539  -1.553889   \n",
      "2     1   2        0           0 -1.438516 -1.181732  0.895539  -1.553889   \n",
      "3     1   3        0           0 -1.334648 -1.093281  0.636370  -1.553889   \n",
      "4     1   4        0           0 -1.334648 -1.093281  0.636370  -1.553889   \n",
      "\n",
      "     casual  registered  ...  weekday_Monday  weekday_Saturday  \\\n",
      "0 -0.662755   -0.930189  ...           False              True   \n",
      "1 -0.561343   -0.804655  ...           False              True   \n",
      "2 -0.622190   -0.837690  ...           False              True   \n",
      "3 -0.662755   -0.950010  ...           False              True   \n",
      "4 -0.723603   -1.009474  ...           False              True   \n",
      "\n",
      "   weekday_Sunday  weekday_Thursday  weekday_Tuesday  weekday_Wednesday  \\\n",
      "0           False             False            False              False   \n",
      "1           False             False            False              False   \n",
      "2           False             False            False              False   \n",
      "3           False             False            False              False   \n",
      "4           False             False            False              False   \n",
      "\n",
      "   weathersit_Clear/Few clouds  weathersit_Heavy Rain/Snow  \\\n",
      "0                         True                       False   \n",
      "1                         True                       False   \n",
      "2                         True                       False   \n",
      "3                         True                       False   \n",
      "4                         True                       False   \n",
      "\n",
      "   weathersit_Light Snow/Rain  weathersit_Mist/Cloudy  \n",
      "0                       False                   False  \n",
      "1                       False                   False  \n",
      "2                       False                   False  \n",
      "3                       False                   False  \n",
      "4                       False                   False  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 28 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   mnth                         17379 non-null  int64  \n",
      " 1   hr                           17379 non-null  int64  \n",
      " 2   holiday                      17379 non-null  int64  \n",
      " 3   workingday                   17379 non-null  int64  \n",
      " 4   temp                         17379 non-null  float64\n",
      " 5   atemp                        17379 non-null  float64\n",
      " 6   hum                          17379 non-null  float64\n",
      " 7   windspeed                    17379 non-null  float64\n",
      " 8   casual                       17379 non-null  float64\n",
      " 9   registered                   17379 non-null  float64\n",
      " 10  cnt                          17379 non-null  float64\n",
      " 11  season_fall                  17379 non-null  bool   \n",
      " 12  season_spring                17379 non-null  bool   \n",
      " 13  season_summer                17379 non-null  bool   \n",
      " 14  season_winter                17379 non-null  bool   \n",
      " 15  year_2011                    17379 non-null  bool   \n",
      " 16  year_2012                    17379 non-null  bool   \n",
      " 17  weekday_Friday               17379 non-null  bool   \n",
      " 18  weekday_Monday               17379 non-null  bool   \n",
      " 19  weekday_Saturday             17379 non-null  bool   \n",
      " 20  weekday_Sunday               17379 non-null  bool   \n",
      " 21  weekday_Thursday             17379 non-null  bool   \n",
      " 22  weekday_Tuesday              17379 non-null  bool   \n",
      " 23  weekday_Wednesday            17379 non-null  bool   \n",
      " 24  weathersit_Clear/Few clouds  17379 non-null  bool   \n",
      " 25  weathersit_Heavy Rain/Snow   17379 non-null  bool   \n",
      " 26  weathersit_Light Snow/Rain   17379 non-null  bool   \n",
      " 27  weathersit_Mist/Cloudy       17379 non-null  bool   \n",
      "dtypes: bool(17), float64(7), int64(4)\n",
      "memory usage: 1.7 MB\n",
      "\n",
      "Basic Statistics:\n",
      "            mnth         hr    holiday  workingday       temp      atemp  \\\n",
      "count  17379.000  17379.000  17379.000   17379.000  17379.000  17379.000   \n",
      "mean       6.538     11.547      0.029       0.683      0.000     -0.000   \n",
      "std        3.439      6.914      0.167       0.465      1.000      1.000   \n",
      "min        1.000      0.000      0.000       0.000     -2.477     -2.769   \n",
      "25%        4.000      6.000      0.000       0.000     -0.815     -0.829   \n",
      "50%        7.000     12.000      0.000       1.000      0.016      0.053   \n",
      "75%       10.000     18.000      0.000       1.000      0.847      0.846   \n",
      "max       12.000     23.000      1.000       1.000      2.612      3.051   \n",
      "\n",
      "             hum  windspeed     casual  registered        cnt  \n",
      "count  17379.000  17379.000  17379.000   17379.000  17379.000  \n",
      "mean       0.000      0.000      0.000      -0.000     -0.000  \n",
      "std        1.000      1.000      1.000       1.000      1.000  \n",
      "min       -3.251     -1.554     -0.724      -1.016     -1.039  \n",
      "25%       -0.763     -0.700     -0.642      -0.791     -0.824  \n",
      "50%        0.014      0.032     -0.379      -0.256     -0.262  \n",
      "75%        0.792      0.520      0.250       0.437      0.505  \n",
      "max        1.932      5.400      6.720       4.838      4.342  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df2 = pd.read_csv(\"bike_sharing_dataset/day.csv\")\n",
    "# Missing values\n",
    "sum_nan_values = df2.isna().sum()\n",
    "print(sum_nan_values)\n",
    "print(\"\\nMissing values (%):\")\n",
    "print((sum_nan_values / len(df2) * 100).round(2))\n",
    "\n",
    "# Duplicates\n",
    "print(f\"\\nTotal duplicate rows: {df2.duplicated().sum()}\")\n",
    "print(f\"Duplicates (keep first): {df2.duplicated(keep='first').sum()}\")\n",
    "\n",
    "# Remove duplicates if needed\n",
    "df2 = df2.drop_duplicates(keep='first')\n",
    "\n",
    "# Drop non-informative columns\n",
    "# instant: just a sequence index, no predictive value\n",
    "# dteday: date string, hour already captures temporal patterns\n",
    "\n",
    "df2_clean = df2.drop(columns=[\"instant\", \"dteday\"])\n",
    "\n",
    "print(f\"Columns after cleaning: {df2_clean.columns.tolist()}\")\n",
    "print(f\"Shape: {df2_clean.shape}\")\n",
    "\n",
    "# Validate data integrity for data consistency issues: casual users + registered users should equal total count\n",
    "validation_error = (df2_clean[\"casual\"] + df2_clean[\"registered\"] - df2_clean[\"cnt\"]).abs().sum()\n",
    "\n",
    "print(f\"Data integrity check (should be 0): {validation_error}\")\n",
    "\n",
    "if validation_error == 0:\n",
    "    print(\"Data is consistent: casual + registered = cnt\")\n",
    "else:\n",
    "    print(\"Data is inconsistent!\")\n",
    "\n",
    "# Encode categorical variables to numerical format\n",
    "season_labels = {1: \"spring\", 2: \"summer\", 3: \"fall\", 4: \"winter\"}\n",
    "year_labels = {0: \"2011\", 1: \"2012\"}\n",
    "weekday_labels = {0: \"Sunday\", 1: \"Monday\", 2: \"Tuesday\", 3: \"Wednesday\", 4: \"Thursday\", 5: \"Friday\", 6: \"Saturday\"}\n",
    "weathersit_labels = {1: \"Clear/Few clouds\", 2: \"Mist/Cloudy\", 3: \"Light Snow/Rain\", 4: \"Heavy Rain/Snow\"}\n",
    "\n",
    "season_dummies = pd.get_dummies(df2_clean[\"season\"].map(season_labels), prefix=\"season\")\n",
    "year_dummies = pd.get_dummies(df2_clean[\"yr\"].map(year_labels), prefix=\"year\")\n",
    "weekday_dummies = pd.get_dummies(df2_clean[\"weekday\"].map(weekday_labels), prefix=\"weekday\")\n",
    "weathersit_dummies = pd.get_dummies(df2_clean[\"weathersit\"].map(weathersit_labels), prefix=\"weathersit\")\n",
    "\n",
    "df2_encoded = pd.concat([\n",
    "    df2_clean.drop(columns=[\"season\", \"weathersit\", \"weekday\", \"yr\"]),\n",
    "    season_dummies,\n",
    "    year_dummies,\n",
    "    weekday_dummies,\n",
    "    weathersit_dummies\n",
    "], axis=1)\n",
    "\n",
    "print(f\"Columns after encoding: {df2_encoded.columns.tolist()}\")\n",
    "print(f\"Shape after encoding: {df2_encoded.shape}\")\n",
    "print(f\"\\nData types:\\n{df2_encoded.dtypes}\")\n",
    "\n",
    "numerical_cols = [\n",
    "    \"temp\", \"atemp\", \"hum\", \"windspeed\",\n",
    "    \"cnt\", \"casual\", \"registered\"\n",
    "]\n",
    "\n",
    "df2_encoded[numerical_cols] = scaler.fit_transform(\n",
    "    df2_encoded[numerical_cols]\n",
    ")\n",
    "\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {df2_encoded.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df2_encoded.head())\n",
    "print(f\"\\nData Info:\")\n",
    "df_encoded.info()\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(df2_encoded.describe().round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
